

There are two possible situations that led to this error:
  1. You haven&#39;t copied the config.toml yet. See https://github.com/olOwOlo/hugo-theme-even#installation 
  2. You have an incompatible update. See https://github.com/olOwOlo/hugo-theme-even/blob/master/CHANGELOG.md#400-2018-11-06 

有两种可能的情况会导致这个错误发生:
  1. 你还没有复制 config.toml 参考 https://github.com/olOwOlo/hugo-theme-even/blob/master/README-zh.md#installation 
  2. 你进行了一次不兼容的更新 参考 https://github.com/olOwOlo/hugo-theme-even/blob/master/CHANGELOG.md#400-2018-11-06 
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>C&#43;&#43; Ep16:The Concurrency API(1) - Learning Hardy</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="" /><meta name="description" content="Item 35:优先考虑基于任务编程，而不是线程编程   如果你想异步地运行函数 doAsyncWork，你有两个基本的选择。你可以创建一个 std::thread， 用它来运行 doAsyncWork，因此这是基于线程（ thread-based ）的方法： int doAsyncWork(); std::thread t(doAsyncWork);    或者你把 doAsynWork 传递给 std::async，一个叫做基于任务（ task-based ）的策略： auto fut = std::async(doAsyncWork); // &amp;#34;fut&amp;#34; for &amp;#34;future&amp;#34;    在这种调用中，传递给 std::async 的函数对象被认为是一个任务（task）。  基于任务的方法通常比基于线程实现的相对物要好，我们看到基于任务的方法代码量更少，这已经是展示了一些原因了。在这里，doAsyncWork 会返回一个值， 我们有理由假定调用 doAsyncWork 的代码对这个返回值有兴趣。在基于线程的调用中，没有直接的办法获取到它；而在基于任务的调用中，这很容易， 因为 std::asyn 返回的 future 提供了一个函数 get 来获取返回值。如果 doAsyncWork 函数发出了一个异常，get 函数是很重要的，它能取到这个异常。 在基于线程的方法中，如果 doAsyncWork 抛出了异常，程序就死亡了（通过调用 std::terminate）。  基于线程编程和基于任务编程的一个更基础的区别是，基于任务编程表现出更高级别的抽象。它让你免受线程管理的细节， 这让我想起了我需要总结“线程”在 C&#43;&#43;并发软件里的三个意思：    硬件线程 是一种负责计算的线程。现代机器体系结构为每个 CPU 核心提供一个或多个硬件线程。    软件线程 （又称为操作系统线程或系统线程）是由操作系统管理和为硬件线程进行调度的线程。软件线程创建的数量通常会比硬件线程多，因为当一个软件线程阻塞了（例如，I/O 操作，等待锁或者条件变量），运行另一个非阻塞的线程能提供吞吐率。    std::thread 是 C&#43;&#43;进程里的对象，它在自身内部操作软件线程。一些 std::thread 对象表示为“null”句柄，相当于不持有软件线程，因为它们处于默认构造状态（因此没有需要执行的函数），它要么被移动过了（那么，移动操作的目的 std::thread 对象会操作软件线程），要么被 join 了（std::thread 对象要执行的函数运行结束），要么被 detach 了（std::thread 对象和它内部软件线程的连接被切断了，即 thread 对象和软件线程分离了）。    软件线程是一种受限的资源，如果你想创建的线程数量多于系统提供的数量，会抛出 std::system_error 异常。就算你规定函数不能抛出异常，这个异常也会抛出。 例如，就算你把 doAsyncWork 声明为 noexcept， int doAsyncWork() noexcept; // see Item 14 for noexcept    这语句还是可能会抛出异常： std::thread t(doAsyncWork); // throws if no more  // threads are available    写得好的软件必须想个办法解决这个可能性，但如何解决呢？一个办法是在当前线程运行 doAsyncWork，但这会导致负载不均衡的问题， 而且，如果当前线程是个 GUI 线程，会导致响应时间变长。另一个方法是等待某些已存在的软件线程完成工作，然后再尝试创建一个新的 std::thread 对象， 但是有可能发生这种事情：已存在的线程在等待 doAsyncWork 的处理（例如，doAsyncWorkd 的返回值，或者通知条件变量）。  即使你的没有用完线程，你还是会有 oversubscription （过载）的问题——当就绪状态（即非阻塞）的软件线程多于硬件线程的时候。如果发生了那种事， 调度线程（通常是操作系统的一部分）会为软件线程分配 CPU 时间片，一个线程的时间片用完，就运行另一个线程，这其中发生了上下文切换。 这种上下文切换会增加系统的线程管理开销。这种情况下，（1）CPU 缓存会持有那个软件线程（即，它们会含有对于那软件线程有用的一些数据和一些指令）， 而（2）CPU 核心上“新”运行的软件线程“污染”了 CPU 缓存上“旧的”线程数据（它曾经在该 CPU 核心运行过，且可能再次调度到该 CPU 核心运行）。  避免 oversubscription 是很困难的，因为软件系统和硬件线程的最佳比例是取决于软件线程多久需要执行一次，而这是会动态改变的， 例如，当一个线程从 IO 消耗型转换为 CPU 消耗型时。这最佳比例也取决于上下文切换的开销和软件线程使用 CPU 缓存的效率。再进一步说， 硬件线程的数量和 CPU 缓存的细节（例如，缓存多大和多快）是取决于机器的体系结构，所以即使你在一个平台上让你的应用避免了 oversubscription（保持硬件繁忙工作），也不能保证在另一种机器上你的方案能工作得好。  如果你把这些问题扔给某个人去做，你的生活就很惬意啦，然后使用 std::async 就能显式地做这件事： auto fut = std::async(doAsyncWork); // onus of thread mgmt is  // on implementer of  // the Standard Library    这个调用把线程管理的责任转交给 C&#43;&#43;标准库的实现者。例如，得到线程超标的异常的可能性绝大幅度减少，因为这个调用可能从不产生这个异常。 “它是怎样做到的呢？”你可能好奇，“如果我申请多于系统提供的线程，使用 std::thread 和使用 std::async 有区别吗？”答案是有区别， 因为当用默认发射策略（看条款 36）调用 std::async 时，不能保证它会创建一个新的软件线程。而且，它允许调度器把指定函数（例如，doAsyncWork） 运行在——请求 doAsyncWork 结果的线程中（例如，那个线程调用了 get 或者对 fut 使用 wait），如果系统 oversubsrcibed 或线程耗尽时， 合理的调度器可以利用这个优势  如果你想用“在需求函数结果的线程上运行该函数”来欺骗自己，我提起过这会导致负载均衡的问题，这问题不会消失， 只是由 std::async 和调度器来面对它们，而不是你。但是，当涉及到负载均衡问题时，调度器比你更加了解当前机器发生了什么， 因为它管理所有进程的线程，而不是只是你的代码。  使用 std::async，GUI 线程的响应性也是有问题的，因为调度器没有办法知道哪个线程需求紧凑的响应性。在这种情况下， 你可以把 std::lanuch::async 发射策略传递给 std::async，它那可以保证你想要运行的函数马上会在另一个线程中执行（看条款 36）。  最新技术水平的线程调度器使用了系统范围的线程池来避免 oversubscription，而且调度器通过工作窃取算法来提高了硬件核心的负载均衡能力。 C&#43;&#43;标准库没有要求线程池或者工作窃取算法，而且，实话说，C&#43;&#43;11 并发技术的一些实现细节让我们很难利用到它们。 但是，一些供应商会在它们的标准库实现中利用这种技术，所以我们有理由期待 C&#43;&#43;并发库会继续进步。如果你使用基于任务的方法进行编程，当它以后变智能了， 你会自动获取到好处。另一方面，如果你直接使用 std::thread 进行编程，你要承担着处理线程耗尽、oversubscription、负载均衡的压力， 更不用提你在程序中对这些问题的处理方案能否应用在同一台机器的另一个进程上。  比起基于线程编程，基于任务的设计能分担你的线程管理之痛，而且它提供了一种很自然的方式，让你检查异步执行函数的结果（即，返回值或异常）。 但是，有几种情况直接使用 std::thread 更适合，它们包括    你需要使用内部的特定平台线程的 API。C&#43;&#43;并发 API 通常是以特定平台的低级 API 实现的，通常使用 pthread 或 Window’s Thread。它们提供的 API 比 C&#43;&#43;提供的要多（例如，C&#43;&#43;没有线程优先级的概念）。为了获取内部线程实现的 API，std::thread 对象有一个 native_handle 成员函数，而 std::future（即 std::async 返回的类型）没有类似的东西。    你需要且能够在你的应用中优化线程的用法。例如，你要在一个固定的机器平台上部署一个单进程的服务器软件。    你需要在 C&#43;&#43;并发 API 之上实现线程技术。例如，实现一个 C&#43;&#43;不提供的线程池。    不过，这些都是不常见的情况。大多数时候，你应该选择基于任务的设计，来代替线程。 记住     std::thread 的 API 没有提供直接获取异步运行函数返回值的方法，而且，如果这些函数抛出异常，程序会被终止。    基于线程编程需要手动地管理：线程耗尽、oversubscription、负载均衡、适配新平台。    借助默认发射策略的 std::async，进行基于任务编程可以解决上面提到的大部分问题   Item 36:如果异步执行是必需的，指定 std::launch::async 策略   当你调用 std::async 来执行一个函数（或一个可执行对象）时，你通常希望函数是异步执行的。但你没有要求 std::async 必须这样做， 函数是根据 std::async 的发射策略（ launch policy ）来执行的。有两个标准策略，每个都是通过 std::launch 局部枚举（scoped enum， 看条款 10） 来表示。假设一个函数 f 要传递给 std::launch 执行，    std::launch::async 发射策略意味着函数 f 必须异步执行，即在另一线程执行。    std::launch::deferred 发射策略意味着函数 f 可能只会在——std::async 返回的 future 对象调用 get 或 wait 时——执行。那就是，执行会推迟到其中一个调用发生。当调用 get 或 wait 时，f 会同步执行，即，调用者会阻塞直到 f 运行结束。如果 get 或 wait 没有被调用，f 就绝对不会执行。    可能很奇怪，std::async 的默认发射策略——它的默认策略是你不能显式指定的——不是两者其中的一种，相反，是两者进行或运算。下面两个函数完全是相同的意思： auto fut1 = std::async(f); // run f using  // default launch  // policy  auto fut2 = std::async(std::launch::async | // run f either 	std::launch::deferred, // async or 	f); // deferred    默认的发射策略允许异步或同步执行函数 f，就如条款 35 指出，这个灵活性让 std::async 与标准库的线程管理组件一起承担线程创建和销毁、避免过载、 负责均衡的责任。这让用 std::async 进行并发编程变得很方便。  但用 std::async 的默认发射策略会有一些有趣的含义。这语句给定一个线程 t 执行 f， auto fut = std::async(f); // run f using default launch policy      没有办法预知函数 f 是否会和线程 t 并发执行，因为 f 可能会被调度为推迟执行。    没有办法预知函数 f 是否运行在——与调用 get 或 wait 函数的线程不同的——线程。如果那个线程是 t，这句话的含义是没有办法预知 f 是否会运行在与 t 不同的线程    可能没有办法预知函数 f 是否执行完全，因为没有办法保证 fut 会调用 get 或 wait。    默认发射策略的调度灵活性经常会混淆使用 thread_local 变量，这意味着如果 f 写或读这种线程本地存储(Thread Local Storage，TLS)，预知取到哪个线程的本地变量是不可能的： auto fut = std::async(f); // TLS for f possibly for  // independent thread, but  // possibly for thread  // invoking get or wait on fut    它也影响了基于 wait 循环中的超时情况，因为对一个推迟（策略为 deferred）的任务（看条款 35）调用 wait_for 或者 wait_until 会返回值 std::launch::deferred 。这意味着下面的循环，看起来最终会停止，但是，实际上可能会一直运行： using namespace std::literals; // for C&#43;&#43;14 duration  // suffixes; see Item 34  void f() // f sleeps for 1 second,  { // then returns 	std::this_thread::sleep_for(1s); } auto fut = std::async(f); // run f asynchronously  // (conceptually)  while (fut." />






<meta name="generator" content="Hugo 0.57.0 with even 4.0.0" />


<link rel="canonical" href="https://hardy5012.github.io/post/c&#43;&#43;-ep16the-concurrency-api1/" />
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">


<link href="/dist/even.c2a46f00.min.css" rel="stylesheet">



<meta property="og:title" content="C&#43;&#43; Ep16:The Concurrency API(1)" />
<meta property="og:description" content="Item 35:优先考虑基于任务编程，而不是线程编程   如果你想异步地运行函数 doAsyncWork，你有两个基本的选择。你可以创建一个 std::thread， 用它来运行 doAsyncWork，因此这是基于线程（ thread-based ）的方法： int doAsyncWork(); std::thread t(doAsyncWork);    或者你把 doAsynWork 传递给 std::async，一个叫做基于任务（ task-based ）的策略： auto fut = std::async(doAsyncWork); // &#34;fut&#34; for &#34;future&#34;    在这种调用中，传递给 std::async 的函数对象被认为是一个任务（task）。  基于任务的方法通常比基于线程实现的相对物要好，我们看到基于任务的方法代码量更少，这已经是展示了一些原因了。在这里，doAsyncWork 会返回一个值， 我们有理由假定调用 doAsyncWork 的代码对这个返回值有兴趣。在基于线程的调用中，没有直接的办法获取到它；而在基于任务的调用中，这很容易， 因为 std::asyn 返回的 future 提供了一个函数 get 来获取返回值。如果 doAsyncWork 函数发出了一个异常，get 函数是很重要的，它能取到这个异常。 在基于线程的方法中，如果 doAsyncWork 抛出了异常，程序就死亡了（通过调用 std::terminate）。  基于线程编程和基于任务编程的一个更基础的区别是，基于任务编程表现出更高级别的抽象。它让你免受线程管理的细节， 这让我想起了我需要总结“线程”在 C&#43;&#43;并发软件里的三个意思：    硬件线程 是一种负责计算的线程。现代机器体系结构为每个 CPU 核心提供一个或多个硬件线程。    软件线程 （又称为操作系统线程或系统线程）是由操作系统管理和为硬件线程进行调度的线程。软件线程创建的数量通常会比硬件线程多，因为当一个软件线程阻塞了（例如，I/O 操作，等待锁或者条件变量），运行另一个非阻塞的线程能提供吞吐率。    std::thread 是 C&#43;&#43;进程里的对象，它在自身内部操作软件线程。一些 std::thread 对象表示为“null”句柄，相当于不持有软件线程，因为它们处于默认构造状态（因此没有需要执行的函数），它要么被移动过了（那么，移动操作的目的 std::thread 对象会操作软件线程），要么被 join 了（std::thread 对象要执行的函数运行结束），要么被 detach 了（std::thread 对象和它内部软件线程的连接被切断了，即 thread 对象和软件线程分离了）。    软件线程是一种受限的资源，如果你想创建的线程数量多于系统提供的数量，会抛出 std::system_error 异常。就算你规定函数不能抛出异常，这个异常也会抛出。 例如，就算你把 doAsyncWork 声明为 noexcept， int doAsyncWork() noexcept; // see Item 14 for noexcept    这语句还是可能会抛出异常： std::thread t(doAsyncWork); // throws if no more  // threads are available    写得好的软件必须想个办法解决这个可能性，但如何解决呢？一个办法是在当前线程运行 doAsyncWork，但这会导致负载不均衡的问题， 而且，如果当前线程是个 GUI 线程，会导致响应时间变长。另一个方法是等待某些已存在的软件线程完成工作，然后再尝试创建一个新的 std::thread 对象， 但是有可能发生这种事情：已存在的线程在等待 doAsyncWork 的处理（例如，doAsyncWorkd 的返回值，或者通知条件变量）。  即使你的没有用完线程，你还是会有 oversubscription （过载）的问题——当就绪状态（即非阻塞）的软件线程多于硬件线程的时候。如果发生了那种事， 调度线程（通常是操作系统的一部分）会为软件线程分配 CPU 时间片，一个线程的时间片用完，就运行另一个线程，这其中发生了上下文切换。 这种上下文切换会增加系统的线程管理开销。这种情况下，（1）CPU 缓存会持有那个软件线程（即，它们会含有对于那软件线程有用的一些数据和一些指令）， 而（2）CPU 核心上“新”运行的软件线程“污染”了 CPU 缓存上“旧的”线程数据（它曾经在该 CPU 核心运行过，且可能再次调度到该 CPU 核心运行）。  避免 oversubscription 是很困难的，因为软件系统和硬件线程的最佳比例是取决于软件线程多久需要执行一次，而这是会动态改变的， 例如，当一个线程从 IO 消耗型转换为 CPU 消耗型时。这最佳比例也取决于上下文切换的开销和软件线程使用 CPU 缓存的效率。再进一步说， 硬件线程的数量和 CPU 缓存的细节（例如，缓存多大和多快）是取决于机器的体系结构，所以即使你在一个平台上让你的应用避免了 oversubscription（保持硬件繁忙工作），也不能保证在另一种机器上你的方案能工作得好。  如果你把这些问题扔给某个人去做，你的生活就很惬意啦，然后使用 std::async 就能显式地做这件事： auto fut = std::async(doAsyncWork); // onus of thread mgmt is  // on implementer of  // the Standard Library    这个调用把线程管理的责任转交给 C&#43;&#43;标准库的实现者。例如，得到线程超标的异常的可能性绝大幅度减少，因为这个调用可能从不产生这个异常。 “它是怎样做到的呢？”你可能好奇，“如果我申请多于系统提供的线程，使用 std::thread 和使用 std::async 有区别吗？”答案是有区别， 因为当用默认发射策略（看条款 36）调用 std::async 时，不能保证它会创建一个新的软件线程。而且，它允许调度器把指定函数（例如，doAsyncWork） 运行在——请求 doAsyncWork 结果的线程中（例如，那个线程调用了 get 或者对 fut 使用 wait），如果系统 oversubsrcibed 或线程耗尽时， 合理的调度器可以利用这个优势  如果你想用“在需求函数结果的线程上运行该函数”来欺骗自己，我提起过这会导致负载均衡的问题，这问题不会消失， 只是由 std::async 和调度器来面对它们，而不是你。但是，当涉及到负载均衡问题时，调度器比你更加了解当前机器发生了什么， 因为它管理所有进程的线程，而不是只是你的代码。  使用 std::async，GUI 线程的响应性也是有问题的，因为调度器没有办法知道哪个线程需求紧凑的响应性。在这种情况下， 你可以把 std::lanuch::async 发射策略传递给 std::async，它那可以保证你想要运行的函数马上会在另一个线程中执行（看条款 36）。  最新技术水平的线程调度器使用了系统范围的线程池来避免 oversubscription，而且调度器通过工作窃取算法来提高了硬件核心的负载均衡能力。 C&#43;&#43;标准库没有要求线程池或者工作窃取算法，而且，实话说，C&#43;&#43;11 并发技术的一些实现细节让我们很难利用到它们。 但是，一些供应商会在它们的标准库实现中利用这种技术，所以我们有理由期待 C&#43;&#43;并发库会继续进步。如果你使用基于任务的方法进行编程，当它以后变智能了， 你会自动获取到好处。另一方面，如果你直接使用 std::thread 进行编程，你要承担着处理线程耗尽、oversubscription、负载均衡的压力， 更不用提你在程序中对这些问题的处理方案能否应用在同一台机器的另一个进程上。  比起基于线程编程，基于任务的设计能分担你的线程管理之痛，而且它提供了一种很自然的方式，让你检查异步执行函数的结果（即，返回值或异常）。 但是，有几种情况直接使用 std::thread 更适合，它们包括    你需要使用内部的特定平台线程的 API。C&#43;&#43;并发 API 通常是以特定平台的低级 API 实现的，通常使用 pthread 或 Window’s Thread。它们提供的 API 比 C&#43;&#43;提供的要多（例如，C&#43;&#43;没有线程优先级的概念）。为了获取内部线程实现的 API，std::thread 对象有一个 native_handle 成员函数，而 std::future（即 std::async 返回的类型）没有类似的东西。    你需要且能够在你的应用中优化线程的用法。例如，你要在一个固定的机器平台上部署一个单进程的服务器软件。    你需要在 C&#43;&#43;并发 API 之上实现线程技术。例如，实现一个 C&#43;&#43;不提供的线程池。    不过，这些都是不常见的情况。大多数时候，你应该选择基于任务的设计，来代替线程。 记住     std::thread 的 API 没有提供直接获取异步运行函数返回值的方法，而且，如果这些函数抛出异常，程序会被终止。    基于线程编程需要手动地管理：线程耗尽、oversubscription、负载均衡、适配新平台。    借助默认发射策略的 std::async，进行基于任务编程可以解决上面提到的大部分问题   Item 36:如果异步执行是必需的，指定 std::launch::async 策略   当你调用 std::async 来执行一个函数（或一个可执行对象）时，你通常希望函数是异步执行的。但你没有要求 std::async 必须这样做， 函数是根据 std::async 的发射策略（ launch policy ）来执行的。有两个标准策略，每个都是通过 std::launch 局部枚举（scoped enum， 看条款 10） 来表示。假设一个函数 f 要传递给 std::launch 执行，    std::launch::async 发射策略意味着函数 f 必须异步执行，即在另一线程执行。    std::launch::deferred 发射策略意味着函数 f 可能只会在——std::async 返回的 future 对象调用 get 或 wait 时——执行。那就是，执行会推迟到其中一个调用发生。当调用 get 或 wait 时，f 会同步执行，即，调用者会阻塞直到 f 运行结束。如果 get 或 wait 没有被调用，f 就绝对不会执行。    可能很奇怪，std::async 的默认发射策略——它的默认策略是你不能显式指定的——不是两者其中的一种，相反，是两者进行或运算。下面两个函数完全是相同的意思： auto fut1 = std::async(f); // run f using  // default launch  // policy  auto fut2 = std::async(std::launch::async | // run f either 	std::launch::deferred, // async or 	f); // deferred    默认的发射策略允许异步或同步执行函数 f，就如条款 35 指出，这个灵活性让 std::async 与标准库的线程管理组件一起承担线程创建和销毁、避免过载、 负责均衡的责任。这让用 std::async 进行并发编程变得很方便。  但用 std::async 的默认发射策略会有一些有趣的含义。这语句给定一个线程 t 执行 f， auto fut = std::async(f); // run f using default launch policy      没有办法预知函数 f 是否会和线程 t 并发执行，因为 f 可能会被调度为推迟执行。    没有办法预知函数 f 是否运行在——与调用 get 或 wait 函数的线程不同的——线程。如果那个线程是 t，这句话的含义是没有办法预知 f 是否会运行在与 t 不同的线程    可能没有办法预知函数 f 是否执行完全，因为没有办法保证 fut 会调用 get 或 wait。    默认发射策略的调度灵活性经常会混淆使用 thread_local 变量，这意味着如果 f 写或读这种线程本地存储(Thread Local Storage，TLS)，预知取到哪个线程的本地变量是不可能的： auto fut = std::async(f); // TLS for f possibly for  // independent thread, but  // possibly for thread  // invoking get or wait on fut    它也影响了基于 wait 循环中的超时情况，因为对一个推迟（策略为 deferred）的任务（看条款 35）调用 wait_for 或者 wait_until 会返回值 std::launch::deferred 。这意味着下面的循环，看起来最终会停止，但是，实际上可能会一直运行： using namespace std::literals; // for C&#43;&#43;14 duration  // suffixes; see Item 34  void f() // f sleeps for 1 second,  { // then returns 	std::this_thread::sleep_for(1s); } auto fut = std::async(f); // run f asynchronously  // (conceptually)  while (fut." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hardy5012.github.io/post/c&#43;&#43;-ep16the-concurrency-api1/" />
<meta property="article:published_time" content="2018-01-15T00:00:00+00:00" />
<meta property="article:modified_time" content="2018-01-15T00:00:00+00:00" />
<meta itemprop="name" content="C&#43;&#43; Ep16:The Concurrency API(1)">
<meta itemprop="description" content="Item 35:优先考虑基于任务编程，而不是线程编程   如果你想异步地运行函数 doAsyncWork，你有两个基本的选择。你可以创建一个 std::thread， 用它来运行 doAsyncWork，因此这是基于线程（ thread-based ）的方法： int doAsyncWork(); std::thread t(doAsyncWork);    或者你把 doAsynWork 传递给 std::async，一个叫做基于任务（ task-based ）的策略： auto fut = std::async(doAsyncWork); // &#34;fut&#34; for &#34;future&#34;    在这种调用中，传递给 std::async 的函数对象被认为是一个任务（task）。  基于任务的方法通常比基于线程实现的相对物要好，我们看到基于任务的方法代码量更少，这已经是展示了一些原因了。在这里，doAsyncWork 会返回一个值， 我们有理由假定调用 doAsyncWork 的代码对这个返回值有兴趣。在基于线程的调用中，没有直接的办法获取到它；而在基于任务的调用中，这很容易， 因为 std::asyn 返回的 future 提供了一个函数 get 来获取返回值。如果 doAsyncWork 函数发出了一个异常，get 函数是很重要的，它能取到这个异常。 在基于线程的方法中，如果 doAsyncWork 抛出了异常，程序就死亡了（通过调用 std::terminate）。  基于线程编程和基于任务编程的一个更基础的区别是，基于任务编程表现出更高级别的抽象。它让你免受线程管理的细节， 这让我想起了我需要总结“线程”在 C&#43;&#43;并发软件里的三个意思：    硬件线程 是一种负责计算的线程。现代机器体系结构为每个 CPU 核心提供一个或多个硬件线程。    软件线程 （又称为操作系统线程或系统线程）是由操作系统管理和为硬件线程进行调度的线程。软件线程创建的数量通常会比硬件线程多，因为当一个软件线程阻塞了（例如，I/O 操作，等待锁或者条件变量），运行另一个非阻塞的线程能提供吞吐率。    std::thread 是 C&#43;&#43;进程里的对象，它在自身内部操作软件线程。一些 std::thread 对象表示为“null”句柄，相当于不持有软件线程，因为它们处于默认构造状态（因此没有需要执行的函数），它要么被移动过了（那么，移动操作的目的 std::thread 对象会操作软件线程），要么被 join 了（std::thread 对象要执行的函数运行结束），要么被 detach 了（std::thread 对象和它内部软件线程的连接被切断了，即 thread 对象和软件线程分离了）。    软件线程是一种受限的资源，如果你想创建的线程数量多于系统提供的数量，会抛出 std::system_error 异常。就算你规定函数不能抛出异常，这个异常也会抛出。 例如，就算你把 doAsyncWork 声明为 noexcept， int doAsyncWork() noexcept; // see Item 14 for noexcept    这语句还是可能会抛出异常： std::thread t(doAsyncWork); // throws if no more  // threads are available    写得好的软件必须想个办法解决这个可能性，但如何解决呢？一个办法是在当前线程运行 doAsyncWork，但这会导致负载不均衡的问题， 而且，如果当前线程是个 GUI 线程，会导致响应时间变长。另一个方法是等待某些已存在的软件线程完成工作，然后再尝试创建一个新的 std::thread 对象， 但是有可能发生这种事情：已存在的线程在等待 doAsyncWork 的处理（例如，doAsyncWorkd 的返回值，或者通知条件变量）。  即使你的没有用完线程，你还是会有 oversubscription （过载）的问题——当就绪状态（即非阻塞）的软件线程多于硬件线程的时候。如果发生了那种事， 调度线程（通常是操作系统的一部分）会为软件线程分配 CPU 时间片，一个线程的时间片用完，就运行另一个线程，这其中发生了上下文切换。 这种上下文切换会增加系统的线程管理开销。这种情况下，（1）CPU 缓存会持有那个软件线程（即，它们会含有对于那软件线程有用的一些数据和一些指令）， 而（2）CPU 核心上“新”运行的软件线程“污染”了 CPU 缓存上“旧的”线程数据（它曾经在该 CPU 核心运行过，且可能再次调度到该 CPU 核心运行）。  避免 oversubscription 是很困难的，因为软件系统和硬件线程的最佳比例是取决于软件线程多久需要执行一次，而这是会动态改变的， 例如，当一个线程从 IO 消耗型转换为 CPU 消耗型时。这最佳比例也取决于上下文切换的开销和软件线程使用 CPU 缓存的效率。再进一步说， 硬件线程的数量和 CPU 缓存的细节（例如，缓存多大和多快）是取决于机器的体系结构，所以即使你在一个平台上让你的应用避免了 oversubscription（保持硬件繁忙工作），也不能保证在另一种机器上你的方案能工作得好。  如果你把这些问题扔给某个人去做，你的生活就很惬意啦，然后使用 std::async 就能显式地做这件事： auto fut = std::async(doAsyncWork); // onus of thread mgmt is  // on implementer of  // the Standard Library    这个调用把线程管理的责任转交给 C&#43;&#43;标准库的实现者。例如，得到线程超标的异常的可能性绝大幅度减少，因为这个调用可能从不产生这个异常。 “它是怎样做到的呢？”你可能好奇，“如果我申请多于系统提供的线程，使用 std::thread 和使用 std::async 有区别吗？”答案是有区别， 因为当用默认发射策略（看条款 36）调用 std::async 时，不能保证它会创建一个新的软件线程。而且，它允许调度器把指定函数（例如，doAsyncWork） 运行在——请求 doAsyncWork 结果的线程中（例如，那个线程调用了 get 或者对 fut 使用 wait），如果系统 oversubsrcibed 或线程耗尽时， 合理的调度器可以利用这个优势  如果你想用“在需求函数结果的线程上运行该函数”来欺骗自己，我提起过这会导致负载均衡的问题，这问题不会消失， 只是由 std::async 和调度器来面对它们，而不是你。但是，当涉及到负载均衡问题时，调度器比你更加了解当前机器发生了什么， 因为它管理所有进程的线程，而不是只是你的代码。  使用 std::async，GUI 线程的响应性也是有问题的，因为调度器没有办法知道哪个线程需求紧凑的响应性。在这种情况下， 你可以把 std::lanuch::async 发射策略传递给 std::async，它那可以保证你想要运行的函数马上会在另一个线程中执行（看条款 36）。  最新技术水平的线程调度器使用了系统范围的线程池来避免 oversubscription，而且调度器通过工作窃取算法来提高了硬件核心的负载均衡能力。 C&#43;&#43;标准库没有要求线程池或者工作窃取算法，而且，实话说，C&#43;&#43;11 并发技术的一些实现细节让我们很难利用到它们。 但是，一些供应商会在它们的标准库实现中利用这种技术，所以我们有理由期待 C&#43;&#43;并发库会继续进步。如果你使用基于任务的方法进行编程，当它以后变智能了， 你会自动获取到好处。另一方面，如果你直接使用 std::thread 进行编程，你要承担着处理线程耗尽、oversubscription、负载均衡的压力， 更不用提你在程序中对这些问题的处理方案能否应用在同一台机器的另一个进程上。  比起基于线程编程，基于任务的设计能分担你的线程管理之痛，而且它提供了一种很自然的方式，让你检查异步执行函数的结果（即，返回值或异常）。 但是，有几种情况直接使用 std::thread 更适合，它们包括    你需要使用内部的特定平台线程的 API。C&#43;&#43;并发 API 通常是以特定平台的低级 API 实现的，通常使用 pthread 或 Window’s Thread。它们提供的 API 比 C&#43;&#43;提供的要多（例如，C&#43;&#43;没有线程优先级的概念）。为了获取内部线程实现的 API，std::thread 对象有一个 native_handle 成员函数，而 std::future（即 std::async 返回的类型）没有类似的东西。    你需要且能够在你的应用中优化线程的用法。例如，你要在一个固定的机器平台上部署一个单进程的服务器软件。    你需要在 C&#43;&#43;并发 API 之上实现线程技术。例如，实现一个 C&#43;&#43;不提供的线程池。    不过，这些都是不常见的情况。大多数时候，你应该选择基于任务的设计，来代替线程。 记住     std::thread 的 API 没有提供直接获取异步运行函数返回值的方法，而且，如果这些函数抛出异常，程序会被终止。    基于线程编程需要手动地管理：线程耗尽、oversubscription、负载均衡、适配新平台。    借助默认发射策略的 std::async，进行基于任务编程可以解决上面提到的大部分问题   Item 36:如果异步执行是必需的，指定 std::launch::async 策略   当你调用 std::async 来执行一个函数（或一个可执行对象）时，你通常希望函数是异步执行的。但你没有要求 std::async 必须这样做， 函数是根据 std::async 的发射策略（ launch policy ）来执行的。有两个标准策略，每个都是通过 std::launch 局部枚举（scoped enum， 看条款 10） 来表示。假设一个函数 f 要传递给 std::launch 执行，    std::launch::async 发射策略意味着函数 f 必须异步执行，即在另一线程执行。    std::launch::deferred 发射策略意味着函数 f 可能只会在——std::async 返回的 future 对象调用 get 或 wait 时——执行。那就是，执行会推迟到其中一个调用发生。当调用 get 或 wait 时，f 会同步执行，即，调用者会阻塞直到 f 运行结束。如果 get 或 wait 没有被调用，f 就绝对不会执行。    可能很奇怪，std::async 的默认发射策略——它的默认策略是你不能显式指定的——不是两者其中的一种，相反，是两者进行或运算。下面两个函数完全是相同的意思： auto fut1 = std::async(f); // run f using  // default launch  // policy  auto fut2 = std::async(std::launch::async | // run f either 	std::launch::deferred, // async or 	f); // deferred    默认的发射策略允许异步或同步执行函数 f，就如条款 35 指出，这个灵活性让 std::async 与标准库的线程管理组件一起承担线程创建和销毁、避免过载、 负责均衡的责任。这让用 std::async 进行并发编程变得很方便。  但用 std::async 的默认发射策略会有一些有趣的含义。这语句给定一个线程 t 执行 f， auto fut = std::async(f); // run f using default launch policy      没有办法预知函数 f 是否会和线程 t 并发执行，因为 f 可能会被调度为推迟执行。    没有办法预知函数 f 是否运行在——与调用 get 或 wait 函数的线程不同的——线程。如果那个线程是 t，这句话的含义是没有办法预知 f 是否会运行在与 t 不同的线程    可能没有办法预知函数 f 是否执行完全，因为没有办法保证 fut 会调用 get 或 wait。    默认发射策略的调度灵活性经常会混淆使用 thread_local 变量，这意味着如果 f 写或读这种线程本地存储(Thread Local Storage，TLS)，预知取到哪个线程的本地变量是不可能的： auto fut = std::async(f); // TLS for f possibly for  // independent thread, but  // possibly for thread  // invoking get or wait on fut    它也影响了基于 wait 循环中的超时情况，因为对一个推迟（策略为 deferred）的任务（看条款 35）调用 wait_for 或者 wait_until 会返回值 std::launch::deferred 。这意味着下面的循环，看起来最终会停止，但是，实际上可能会一直运行： using namespace std::literals; // for C&#43;&#43;14 duration  // suffixes; see Item 34  void f() // f sleeps for 1 second,  { // then returns 	std::this_thread::sleep_for(1s); } auto fut = std::async(f); // run f asynchronously  // (conceptually)  while (fut.">


<meta itemprop="datePublished" content="2018-01-15T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-01-15T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="759">



<meta itemprop="keywords" content="C&#43;&#43;," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="C&#43;&#43; Ep16:The Concurrency API(1)"/>
<meta name="twitter:description" content="Item 35:优先考虑基于任务编程，而不是线程编程   如果你想异步地运行函数 doAsyncWork，你有两个基本的选择。你可以创建一个 std::thread， 用它来运行 doAsyncWork，因此这是基于线程（ thread-based ）的方法： int doAsyncWork(); std::thread t(doAsyncWork);    或者你把 doAsynWork 传递给 std::async，一个叫做基于任务（ task-based ）的策略： auto fut = std::async(doAsyncWork); // &#34;fut&#34; for &#34;future&#34;    在这种调用中，传递给 std::async 的函数对象被认为是一个任务（task）。  基于任务的方法通常比基于线程实现的相对物要好，我们看到基于任务的方法代码量更少，这已经是展示了一些原因了。在这里，doAsyncWork 会返回一个值， 我们有理由假定调用 doAsyncWork 的代码对这个返回值有兴趣。在基于线程的调用中，没有直接的办法获取到它；而在基于任务的调用中，这很容易， 因为 std::asyn 返回的 future 提供了一个函数 get 来获取返回值。如果 doAsyncWork 函数发出了一个异常，get 函数是很重要的，它能取到这个异常。 在基于线程的方法中，如果 doAsyncWork 抛出了异常，程序就死亡了（通过调用 std::terminate）。  基于线程编程和基于任务编程的一个更基础的区别是，基于任务编程表现出更高级别的抽象。它让你免受线程管理的细节， 这让我想起了我需要总结“线程”在 C&#43;&#43;并发软件里的三个意思：    硬件线程 是一种负责计算的线程。现代机器体系结构为每个 CPU 核心提供一个或多个硬件线程。    软件线程 （又称为操作系统线程或系统线程）是由操作系统管理和为硬件线程进行调度的线程。软件线程创建的数量通常会比硬件线程多，因为当一个软件线程阻塞了（例如，I/O 操作，等待锁或者条件变量），运行另一个非阻塞的线程能提供吞吐率。    std::thread 是 C&#43;&#43;进程里的对象，它在自身内部操作软件线程。一些 std::thread 对象表示为“null”句柄，相当于不持有软件线程，因为它们处于默认构造状态（因此没有需要执行的函数），它要么被移动过了（那么，移动操作的目的 std::thread 对象会操作软件线程），要么被 join 了（std::thread 对象要执行的函数运行结束），要么被 detach 了（std::thread 对象和它内部软件线程的连接被切断了，即 thread 对象和软件线程分离了）。    软件线程是一种受限的资源，如果你想创建的线程数量多于系统提供的数量，会抛出 std::system_error 异常。就算你规定函数不能抛出异常，这个异常也会抛出。 例如，就算你把 doAsyncWork 声明为 noexcept， int doAsyncWork() noexcept; // see Item 14 for noexcept    这语句还是可能会抛出异常： std::thread t(doAsyncWork); // throws if no more  // threads are available    写得好的软件必须想个办法解决这个可能性，但如何解决呢？一个办法是在当前线程运行 doAsyncWork，但这会导致负载不均衡的问题， 而且，如果当前线程是个 GUI 线程，会导致响应时间变长。另一个方法是等待某些已存在的软件线程完成工作，然后再尝试创建一个新的 std::thread 对象， 但是有可能发生这种事情：已存在的线程在等待 doAsyncWork 的处理（例如，doAsyncWorkd 的返回值，或者通知条件变量）。  即使你的没有用完线程，你还是会有 oversubscription （过载）的问题——当就绪状态（即非阻塞）的软件线程多于硬件线程的时候。如果发生了那种事， 调度线程（通常是操作系统的一部分）会为软件线程分配 CPU 时间片，一个线程的时间片用完，就运行另一个线程，这其中发生了上下文切换。 这种上下文切换会增加系统的线程管理开销。这种情况下，（1）CPU 缓存会持有那个软件线程（即，它们会含有对于那软件线程有用的一些数据和一些指令）， 而（2）CPU 核心上“新”运行的软件线程“污染”了 CPU 缓存上“旧的”线程数据（它曾经在该 CPU 核心运行过，且可能再次调度到该 CPU 核心运行）。  避免 oversubscription 是很困难的，因为软件系统和硬件线程的最佳比例是取决于软件线程多久需要执行一次，而这是会动态改变的， 例如，当一个线程从 IO 消耗型转换为 CPU 消耗型时。这最佳比例也取决于上下文切换的开销和软件线程使用 CPU 缓存的效率。再进一步说， 硬件线程的数量和 CPU 缓存的细节（例如，缓存多大和多快）是取决于机器的体系结构，所以即使你在一个平台上让你的应用避免了 oversubscription（保持硬件繁忙工作），也不能保证在另一种机器上你的方案能工作得好。  如果你把这些问题扔给某个人去做，你的生活就很惬意啦，然后使用 std::async 就能显式地做这件事： auto fut = std::async(doAsyncWork); // onus of thread mgmt is  // on implementer of  // the Standard Library    这个调用把线程管理的责任转交给 C&#43;&#43;标准库的实现者。例如，得到线程超标的异常的可能性绝大幅度减少，因为这个调用可能从不产生这个异常。 “它是怎样做到的呢？”你可能好奇，“如果我申请多于系统提供的线程，使用 std::thread 和使用 std::async 有区别吗？”答案是有区别， 因为当用默认发射策略（看条款 36）调用 std::async 时，不能保证它会创建一个新的软件线程。而且，它允许调度器把指定函数（例如，doAsyncWork） 运行在——请求 doAsyncWork 结果的线程中（例如，那个线程调用了 get 或者对 fut 使用 wait），如果系统 oversubsrcibed 或线程耗尽时， 合理的调度器可以利用这个优势  如果你想用“在需求函数结果的线程上运行该函数”来欺骗自己，我提起过这会导致负载均衡的问题，这问题不会消失， 只是由 std::async 和调度器来面对它们，而不是你。但是，当涉及到负载均衡问题时，调度器比你更加了解当前机器发生了什么， 因为它管理所有进程的线程，而不是只是你的代码。  使用 std::async，GUI 线程的响应性也是有问题的，因为调度器没有办法知道哪个线程需求紧凑的响应性。在这种情况下， 你可以把 std::lanuch::async 发射策略传递给 std::async，它那可以保证你想要运行的函数马上会在另一个线程中执行（看条款 36）。  最新技术水平的线程调度器使用了系统范围的线程池来避免 oversubscription，而且调度器通过工作窃取算法来提高了硬件核心的负载均衡能力。 C&#43;&#43;标准库没有要求线程池或者工作窃取算法，而且，实话说，C&#43;&#43;11 并发技术的一些实现细节让我们很难利用到它们。 但是，一些供应商会在它们的标准库实现中利用这种技术，所以我们有理由期待 C&#43;&#43;并发库会继续进步。如果你使用基于任务的方法进行编程，当它以后变智能了， 你会自动获取到好处。另一方面，如果你直接使用 std::thread 进行编程，你要承担着处理线程耗尽、oversubscription、负载均衡的压力， 更不用提你在程序中对这些问题的处理方案能否应用在同一台机器的另一个进程上。  比起基于线程编程，基于任务的设计能分担你的线程管理之痛，而且它提供了一种很自然的方式，让你检查异步执行函数的结果（即，返回值或异常）。 但是，有几种情况直接使用 std::thread 更适合，它们包括    你需要使用内部的特定平台线程的 API。C&#43;&#43;并发 API 通常是以特定平台的低级 API 实现的，通常使用 pthread 或 Window’s Thread。它们提供的 API 比 C&#43;&#43;提供的要多（例如，C&#43;&#43;没有线程优先级的概念）。为了获取内部线程实现的 API，std::thread 对象有一个 native_handle 成员函数，而 std::future（即 std::async 返回的类型）没有类似的东西。    你需要且能够在你的应用中优化线程的用法。例如，你要在一个固定的机器平台上部署一个单进程的服务器软件。    你需要在 C&#43;&#43;并发 API 之上实现线程技术。例如，实现一个 C&#43;&#43;不提供的线程池。    不过，这些都是不常见的情况。大多数时候，你应该选择基于任务的设计，来代替线程。 记住     std::thread 的 API 没有提供直接获取异步运行函数返回值的方法，而且，如果这些函数抛出异常，程序会被终止。    基于线程编程需要手动地管理：线程耗尽、oversubscription、负载均衡、适配新平台。    借助默认发射策略的 std::async，进行基于任务编程可以解决上面提到的大部分问题   Item 36:如果异步执行是必需的，指定 std::launch::async 策略   当你调用 std::async 来执行一个函数（或一个可执行对象）时，你通常希望函数是异步执行的。但你没有要求 std::async 必须这样做， 函数是根据 std::async 的发射策略（ launch policy ）来执行的。有两个标准策略，每个都是通过 std::launch 局部枚举（scoped enum， 看条款 10） 来表示。假设一个函数 f 要传递给 std::launch 执行，    std::launch::async 发射策略意味着函数 f 必须异步执行，即在另一线程执行。    std::launch::deferred 发射策略意味着函数 f 可能只会在——std::async 返回的 future 对象调用 get 或 wait 时——执行。那就是，执行会推迟到其中一个调用发生。当调用 get 或 wait 时，f 会同步执行，即，调用者会阻塞直到 f 运行结束。如果 get 或 wait 没有被调用，f 就绝对不会执行。    可能很奇怪，std::async 的默认发射策略——它的默认策略是你不能显式指定的——不是两者其中的一种，相反，是两者进行或运算。下面两个函数完全是相同的意思： auto fut1 = std::async(f); // run f using  // default launch  // policy  auto fut2 = std::async(std::launch::async | // run f either 	std::launch::deferred, // async or 	f); // deferred    默认的发射策略允许异步或同步执行函数 f，就如条款 35 指出，这个灵活性让 std::async 与标准库的线程管理组件一起承担线程创建和销毁、避免过载、 负责均衡的责任。这让用 std::async 进行并发编程变得很方便。  但用 std::async 的默认发射策略会有一些有趣的含义。这语句给定一个线程 t 执行 f， auto fut = std::async(f); // run f using default launch policy      没有办法预知函数 f 是否会和线程 t 并发执行，因为 f 可能会被调度为推迟执行。    没有办法预知函数 f 是否运行在——与调用 get 或 wait 函数的线程不同的——线程。如果那个线程是 t，这句话的含义是没有办法预知 f 是否会运行在与 t 不同的线程    可能没有办法预知函数 f 是否执行完全，因为没有办法保证 fut 会调用 get 或 wait。    默认发射策略的调度灵活性经常会混淆使用 thread_local 变量，这意味着如果 f 写或读这种线程本地存储(Thread Local Storage，TLS)，预知取到哪个线程的本地变量是不可能的： auto fut = std::async(f); // TLS for f possibly for  // independent thread, but  // possibly for thread  // invoking get or wait on fut    它也影响了基于 wait 循环中的超时情况，因为对一个推迟（策略为 deferred）的任务（看条款 35）调用 wait_for 或者 wait_until 会返回值 std::launch::deferred 。这意味着下面的循环，看起来最终会停止，但是，实际上可能会一直运行： using namespace std::literals; // for C&#43;&#43;14 duration  // suffixes; see Item 34  void f() // f sleeps for 1 second,  { // then returns 	std::this_thread::sleep_for(1s); } auto fut = std::async(f); // run f asynchronously  // (conceptually)  while (fut."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">Learning Hardy</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/archives/">
        <li class="mobile-menu-item">归档</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">关于</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">Learning Hardy</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/archives/">归档</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">关于</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">C&#43;&#43; Ep16:The Concurrency API(1)</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-01-15 </span>
        <div class="post-category">
            <a href="/categories/modern/"> Modern </a>
            <a href="/categories/c&#43;&#43;/"> C&#43;&#43; </a>
            </div>
        
      </div>
    </header>

    
    <div class="post-content">
      
<h1 id="headline-1">
Item 35:优先考虑基于任务编程，而不是线程编程
</h1>
<p>
如果你想异步地运行函数 doAsyncWork，你有两个基本的选择。你可以创建一个 std::thread，
用它来运行 doAsyncWork，因此这是基于线程（ <strong>thread-based</strong> ）的方法：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">int</span> <span style="color:#a6e22e">doAsyncWork</span>();
  std<span style="color:#f92672">::</span><span style="color:#66d9ef">thread</span> t(doAsyncWork);
</code></pre></div>
</div>
<p>
或者你把 doAsynWork 传递给 std::async，一个叫做基于任务（ <strong>task-based</strong> ）的策略：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(doAsyncWork); <span style="color:#75715e">// &#34;fut&#34; for &#34;future&#34;
</span></code></pre></div>
</div>
<p>
在这种调用中，传递给 std::async 的函数对象被认为是一个任务（task）。
</p>
<!-- more -->
<p>
基于任务的方法通常比基于线程实现的相对物要好，我们看到基于任务的方法代码量更少，这已经是展示了一些原因了。在这里，doAsyncWork 会返回一个值，
我们有理由假定调用 doAsyncWork 的代码对这个返回值有兴趣。在基于线程的调用中，没有直接的办法获取到它；而在基于任务的调用中，这很容易，
因为 std::asyn 返回的 future 提供了一个函数 <strong>get</strong> 来获取返回值。如果 doAsyncWork 函数发出了一个异常，get 函数是很重要的，它能取到这个异常。
在基于线程的方法中，如果 doAsyncWork 抛出了异常，程序就死亡了（通过调用 std::terminate）。
</p>
<p>
基于线程编程和基于任务编程的一个更基础的区别是，基于任务编程表现出更高级别的抽象。它让你免受线程管理的细节，
这让我想起了我需要总结“线程”在 C++并发软件里的三个意思：
</p>
<ul>
<li>
<p>
<strong>硬件线程</strong> 是一种负责计算的线程。现代机器体系结构为每个 CPU 核心提供一个或多个硬件线程。
</p>
</li>
<li>
<p>
<strong>软件线程</strong> （又称为操作系统线程或系统线程）是由操作系统管理和为硬件线程进行调度的线程。软件线程创建的数量通常会比硬件线程多，因为当一个软件线程阻塞了（例如，I/O 操作，等待锁或者条件变量），运行另一个非阻塞的线程能提供吞吐率。
</p>
</li>
<li>
<p>
<strong>std::thread</strong> 是 C++进程里的对象，它在自身内部操作软件线程。一些 std::thread 对象表示为“null”句柄，相当于不持有软件线程，因为它们处于默认构造状态（因此没有需要执行的函数），它要么被移动过了（那么，移动操作的目的 std::thread 对象会操作软件线程），要么被 join 了（std::thread 对象要执行的函数运行结束），要么被 detach 了（std::thread 对象和它内部软件线程的连接被切断了，即 thread 对象和软件线程分离了）。
</p>
</li>
</ul>
<p>
软件线程是一种受限的资源，如果你想创建的线程数量多于系统提供的数量，会抛出 <strong>std::system_error</strong> 异常。就算你规定函数不能抛出异常，这个异常也会抛出。
例如，就算你把 doAsyncWork 声明为 noexcept，
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">int</span> <span style="color:#a6e22e">doAsyncWork</span>() <span style="color:#66d9ef">noexcept</span>; <span style="color:#75715e">// see Item 14 for noexcept
</span></code></pre></div>
</div>
<p>
这语句还是可能会抛出异常：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  std<span style="color:#f92672">::</span><span style="color:#66d9ef">thread</span> t(doAsyncWork); <span style="color:#75715e">// throws if no more
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// threads are available
</span></code></pre></div>
</div>
<p>
写得好的软件必须想个办法解决这个可能性，但如何解决呢？一个办法是在当前线程运行 doAsyncWork，但这会导致负载不均衡的问题，
而且，如果当前线程是个 GUI 线程，会导致响应时间变长。另一个方法是等待某些已存在的软件线程完成工作，然后再尝试创建一个新的 std::thread 对象，
但是有可能发生这种事情：已存在的线程在等待 doAsyncWork 的处理（例如，doAsyncWorkd 的返回值，或者通知条件变量）。
</p>
<p>
即使你的没有用完线程，你还是会有 <strong>oversubscription</strong> （过载）的问题——当就绪状态（即非阻塞）的软件线程多于硬件线程的时候。如果发生了那种事，
调度线程（通常是操作系统的一部分）会为软件线程分配 CPU 时间片，一个线程的时间片用完，就运行另一个线程，这其中发生了上下文切换。
这种上下文切换会增加系统的线程管理开销。这种情况下，（1）CPU 缓存会持有那个软件线程（即，它们会含有对于那软件线程有用的一些数据和一些指令），
而（2）CPU 核心上“新”运行的软件线程“污染”了 CPU 缓存上“旧的”线程数据（它曾经在该 CPU 核心运行过，且可能再次调度到该 CPU 核心运行）。
</p>
<p>
避免 oversubscription 是很困难的，因为软件系统和硬件线程的最佳比例是取决于软件线程多久需要执行一次，而这是会动态改变的，
例如，当一个线程从 IO 消耗型转换为 CPU 消耗型时。这最佳比例也取决于上下文切换的开销和软件线程使用 CPU 缓存的效率。再进一步说，
硬件线程的数量和 CPU 缓存的细节（例如，缓存多大和多快）是取决于机器的体系结构，所以即使你在一个平台上让你的应用避免了
oversubscription（保持硬件繁忙工作），也不能保证在另一种机器上你的方案能工作得好。
</p>
<p>
如果你把这些问题扔给某个人去做，你的生活就很惬意啦，然后使用 std::async 就能显式地做这件事：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(doAsyncWork); <span style="color:#75715e">// onus of thread mgmt is
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// on implementer of
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// the Standard Library
</span></code></pre></div>
</div>
<p>
这个调用把线程管理的责任转交给 C++标准库的实现者。例如，得到线程超标的异常的可能性绝大幅度减少，因为这个调用可能从不产生这个异常。
“它是怎样做到的呢？”你可能好奇，“如果我申请多于系统提供的线程，使用 std::thread 和使用 std::async 有区别吗？”答案是有区别，
因为当用默认发射策略（看条款 36）调用 std::async 时，不能保证它会创建一个新的软件线程。而且，它允许调度器把指定函数（例如，doAsyncWork）
运行在——请求 doAsyncWork 结果的线程中（例如，那个线程调用了 get 或者对 fut 使用 wait），如果系统 oversubsrcibed 或线程耗尽时，
合理的调度器可以利用这个优势
</p>
<p>
如果你想用“在需求函数结果的线程上运行该函数”来欺骗自己，我提起过这会导致负载均衡的问题，这问题不会消失，
只是由 std::async 和调度器来面对它们，而不是你。但是，当涉及到负载均衡问题时，调度器比你更加了解当前机器发生了什么，
因为它管理所有进程的线程，而不是只是你的代码。
</p>
<p>
使用 std::async，GUI 线程的响应性也是有问题的，因为调度器没有办法知道哪个线程需求紧凑的响应性。在这种情况下，
你可以把 <strong>std::lanuch::async</strong> 发射策略传递给 std::async，它那可以保证你想要运行的函数马上会在另一个线程中执行（看条款 36）。
</p>
<p>
最新技术水平的线程调度器使用了系统范围的线程池来避免 oversubscription，而且调度器通过工作窃取算法来提高了硬件核心的负载均衡能力。
C++标准库没有要求线程池或者工作窃取算法，而且，实话说，C++11 并发技术的一些实现细节让我们很难利用到它们。
但是，一些供应商会在它们的标准库实现中利用这种技术，所以我们有理由期待 C++并发库会继续进步。如果你使用基于任务的方法进行编程，当它以后变智能了，
你会自动获取到好处。另一方面，如果你直接使用 std::thread 进行编程，你要承担着处理线程耗尽、oversubscription、负载均衡的压力，
更不用提你在程序中对这些问题的处理方案能否应用在同一台机器的另一个进程上。
</p>
<p>
比起基于线程编程，基于任务的设计能分担你的线程管理之痛，而且它提供了一种很自然的方式，让你检查异步执行函数的结果（即，返回值或异常）。
但是，有几种情况直接使用 std::thread 更适合，它们包括
</p>
<ul>
<li>
<p>
你需要使用内部的特定平台线程的 API。C++并发 API 通常是以特定平台的低级 API 实现的，通常使用 pthread 或 Window’s Thread。它们提供的 API 比 C++提供的要多（例如，C++没有线程优先级的概念）。为了获取内部线程实现的 API，std::thread 对象有一个 native_handle 成员函数，而 std::future（即 std::async 返回的类型）没有类似的东西。
</p>
</li>
<li>
<p>
你需要且能够在你的应用中优化线程的用法。例如，你要在一个固定的机器平台上部署一个单进程的服务器软件。
</p>
</li>
<li>
<p>
你需要在 C++并发 API 之上实现线程技术。例如，实现一个 C++不提供的线程池。
</p>
</li>
</ul>
<p>
不过，这些都是不常见的情况。大多数时候，你应该选择基于任务的设计，来代替线程。
</p>
<h2 id="headline-2">
记住
</h2>
<ul>
<li>
<p>
std::thread 的 API 没有提供直接获取异步运行函数返回值的方法，而且，如果这些函数抛出异常，程序会被终止。
</p>
</li>
<li>
<p>
基于线程编程需要手动地管理：线程耗尽、oversubscription、负载均衡、适配新平台。
</p>
</li>
<li>
<p>
借助默认发射策略的 std::async，进行基于任务编程可以解决上面提到的大部分问题
</p>
</li>
</ul>
<h1 id="headline-3">
Item 36:如果异步执行是必需的，指定 std::launch::async 策略
</h1>
<p>
当你调用 std::async 来执行一个函数（或一个可执行对象）时，你通常希望函数是异步执行的。但你没有要求 std::async 必须这样做，
函数是根据 std::async 的发射策略（ <strong>launch policy</strong> ）来执行的。有两个标准策略，每个都是通过 std::launch 局部枚举（scoped enum， 看条款 10）
来表示。假设一个函数 f 要传递给 std::launch 执行，
</p>
<ul>
<li>
<p>
<strong>std::launch::async</strong> 发射策略意味着函数 f 必须异步执行，即在另一线程执行。
</p>
</li>
<li>
<p>
<strong>std::launch::deferred</strong> 发射策略意味着函数 f 可能只会在——std::async 返回的 future 对象调用  <strong>get</strong>  或 <strong>wait</strong>  时——执行。那就是，执行会推迟到其中一个调用发生。当调用 get 或 wait 时，f 会同步执行，即，调用者会阻塞直到 f 运行结束。如果 get 或 wait 没有被调用，f 就绝对不会执行。
</p>
</li>
</ul>
<p>
可能很奇怪，std::async 的默认发射策略——它的默认策略是你不能显式指定的——不是两者其中的一种，相反，是两者进行或运算。下面两个函数完全是相同的意思：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut1 <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(f); <span style="color:#75715e">// run f using
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// default launch
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// policy
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">auto</span> fut2 <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(std<span style="color:#f92672">::</span>launch<span style="color:#f92672">::</span>async <span style="color:#f92672">|</span> <span style="color:#75715e">// run f either
</span><span style="color:#75715e"></span>						 std<span style="color:#f92672">::</span>launch<span style="color:#f92672">::</span>deferred, <span style="color:#75715e">// async or
</span><span style="color:#75715e"></span>						 f); <span style="color:#75715e">// deferred
</span></code></pre></div>
</div>
<p>
默认的发射策略允许异步或同步执行函数 f，就如条款 35 指出，这个灵活性让 std::async 与标准库的线程管理组件一起承担线程创建和销毁、避免过载、
负责均衡的责任。这让用 std::async 进行并发编程变得很方便。
</p>
<p>
但用 std::async 的默认发射策略会有一些有趣的含义。这语句给定一个线程 t 执行 f，
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(f); <span style="color:#75715e">// run f using default launch policy
</span></code></pre></div>
</div>
<ul>
<li>
<p>
没有办法预知函数 f 是否会和线程 t 并发执行，因为 f 可能会被调度为推迟执行。
</p>
</li>
<li>
<p>
没有办法预知函数 f 是否运行在——与调用 get 或 wait 函数的线程不同的——线程。如果那个线程是 t，这句话的含义是没有办法预知 f 是否会运行在与 t 不同的线程
</p>
</li>
<li>
<p>
可能没有办法预知函数 f 是否执行完全，因为没有办法保证 fut 会调用 get 或 wait。 
</p>
</li>
</ul>
<p>
默认发射策略的调度灵活性经常会混淆使用 <strong>thread_local</strong> 变量，这意味着如果 f 写或读这种线程本地存储(Thread Local Storage，TLS)，预知取到哪个线程的本地变量是不可能的：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(f); <span style="color:#75715e">// TLS for f possibly for
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// independent thread, but
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// possibly for thread
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// invoking get or wait on fut
</span></code></pre></div>
</div>
<p>
它也影响了基于 wait 循环中的超时情况，因为对一个推迟（策略为 deferred）的任务（看条款 35）调用 <strong>wait_for</strong> 或者 <strong>wait_until</strong> 
会返回值 <strong>std::launch::deferred</strong> 。这意味着下面的循环，看起来最终会停止，但是，实际上可能会一直运行：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">using</span> <span style="color:#66d9ef">namespace</span> std<span style="color:#f92672">::</span>literals; <span style="color:#75715e">// for C++14 duration
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// suffixes; see Item 34
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">f</span>() <span style="color:#75715e">// f sleeps for 1 second,
</span><span style="color:#75715e"></span>  { <span style="color:#75715e">// then returns
</span><span style="color:#75715e"></span>	  std<span style="color:#f92672">::</span>this_thread<span style="color:#f92672">::</span>sleep_for(<span style="color:#ae81ff">1</span>s);
  }
  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(f); <span style="color:#75715e">// run f asynchronously
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// (conceptually)
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">while</span> (fut.wait_for(<span style="color:#ae81ff">100</span>ms) <span style="color:#f92672">!=</span> <span style="color:#75715e">// loop until f has
</span><span style="color:#75715e"></span>		 std<span style="color:#f92672">::</span>future_status<span style="color:#f92672">::</span>ready) <span style="color:#75715e">// finished running...
</span><span style="color:#75715e"></span>  { <span style="color:#75715e">// which may never happen!
</span><span style="color:#75715e"></span>	  <span style="color:#960050;background-color:#1e0010">…</span>
		  }
</code></pre></div>
</div>
<p>
如果 f 与调用 std::async 的线程并发执行（即，使用 std::launch::async 发射策略），这里就没有问题（假设 f 能结束执行，不会一直死循环）。
但如果 f 被推迟（deferred）， <strong>fut.wait_for</strong> 将总是返回 <strong>std::future_status::deferred</strong> (需要调用 get 或 wait 来执行)。
那永远也不会等于 std::future_status::ready，所以循环永远不会终止。
</p>
<p>
这种 bug 在开发或单元测试中很容易被忽略，因为它只会在机器负载很重时才会显现。在机器过载（oversubscription）或线程消耗完的状况下，
任务很可能会被推迟（如果使用的是默认发射策略）。总之，如果不是过载或者线程耗尽，运行系统没有理由不调度任务并发执行。
</p>
<p>
解决办法很简单：检查 std::async 返回的 future，看它是否把任务推迟，然后呢，如果真的是那样，就避免进入基于超时的循环。
不幸的是，没有办法直接询问 future 的任务是否被推迟。取而代之的是，你必须调用一个基于超时的函数——例如 wait_for 函数。在这种情况下，
你不用等待任何事情，你只是要看看返回值是否为 std::future_status::deferred，所以请相信这迂回的话语和用 0 来调用  <strong>wait_for</strong> ：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(f); <span style="color:#75715e">// as above
</span><span style="color:#75715e"></span>  <span style="color:#66d9ef">if</span> (fut.wait_for(<span style="color:#ae81ff">0</span>s) <span style="color:#f92672">==</span> <span style="color:#75715e">// if task is
</span><span style="color:#75715e"></span>	  std<span style="color:#f92672">::</span>future_status<span style="color:#f92672">::</span>deferred) <span style="color:#75715e">// deferred...
</span><span style="color:#75715e"></span>  {
  <span style="color:#75715e">// ...use wait or get on fut
</span><span style="color:#75715e"></span>	  <span style="color:#960050;background-color:#1e0010">…</span> <span style="color:#75715e">// to call f synchronously
</span><span style="color:#75715e"></span>		  } <span style="color:#66d9ef">else</span> { <span style="color:#75715e">// task isn&#39;t deferred
</span><span style="color:#75715e"></span>	  <span style="color:#66d9ef">while</span> (fut.wait_for(<span style="color:#ae81ff">100</span>ms) <span style="color:#f92672">!=</span> <span style="color:#75715e">// infinite loop not
</span><span style="color:#75715e"></span>			 std<span style="color:#f92672">::</span>future_status<span style="color:#f92672">::</span>ready) { <span style="color:#75715e">// possible (assuming
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// f finishes)
</span><span style="color:#75715e"></span>		  <span style="color:#960050;background-color:#1e0010">…</span> <span style="color:#75715e">// task is neither deferred nor ready,
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// so do concurrent work until it&#39;s ready
</span><span style="color:#75715e"></span>			  }
	  <span style="color:#960050;background-color:#1e0010">…</span> <span style="color:#75715e">// fut is ready
</span><span style="color:#75715e"></span>		  }
</code></pre></div>
</div>
<p>
考虑多种因素的结论是，只要满足了下面的条件，以默认发射策略对任务使用 std::async 能正常工作：
</p>
<ul>
<li>
<p>
任务不需要与调用 get 或 wait 的线程并发执行。
</p>
</li>
<li>
<p>
修改哪个线程的 thread_local 变量都没关系。
</p>
</li>
<li>
<p>
要么保证 std::async 返回的 future 会调用 get 或 wait，要么你能接受任务可能永远都不执行。
</p>
</li>
<li>
<p>
使用 wait_for 或 wait_unitil 的代码要考虑到任务推迟的可能性。
</p>
</li>
</ul>
<p>
如果其中一个条件没有满足，你很可能是想要确保任务能异步执行。而那样做的方法是，当你调用 std::async 时，把 std::launch::async 作为第一个参数传递给它：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>async(std<span style="color:#f92672">::</span>launch<span style="color:#f92672">::</span>async, f); <span style="color:#75715e">// launch f
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// asynchronously
</span></code></pre></div>
</div>
<p>
事实上， 如果有一个函数的行为像 std::async 那样，但它会自动使用 std::launch::async 作为发射策略，
那样就是一个方便的工作啦！它很容易写出来，棒极了。这是 C++11 的版本：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> F, <span style="color:#66d9ef">typename</span>... Ts<span style="color:#f92672">&gt;</span>
  <span style="color:#66d9ef">inline</span>
  std<span style="color:#f92672">::</span>future<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> std<span style="color:#f92672">::</span>result_of<span style="color:#f92672">&lt;</span>F(Ts...)<span style="color:#f92672">&gt;::</span>type<span style="color:#f92672">&gt;</span>
  reallyAsync(F<span style="color:#f92672">&amp;&amp;</span> f, Ts<span style="color:#f92672">&amp;&amp;</span>... params) <span style="color:#75715e">// return future
</span><span style="color:#75715e"></span>  { <span style="color:#75715e">// for asynchronous
</span><span style="color:#75715e"></span>	  <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>async(std<span style="color:#f92672">::</span>launch<span style="color:#f92672">::</span>async, <span style="color:#75715e">// call to f(params...)
</span><span style="color:#75715e"></span>						std<span style="color:#f92672">::</span>forward<span style="color:#f92672">&lt;</span>F<span style="color:#f92672">&gt;</span>(f),
						std<span style="color:#f92672">::</span>forward<span style="color:#f92672">&lt;</span>Ts<span style="color:#f92672">&gt;</span>(params)...);
  }
</code></pre></div>
</div>
<p>
这个函数接收一个可调用对象 f 和零个或多个参数 params，并且把它们完美转发（看条款 25）给 std::async，传递 std::launch::async 作为发射策略。
就像 std::async 那样，它返回一个类型为 f 调用 params 的结果的 std::future，决定这个结果很容易，因为 <strong>std::result_of</strong> 这个 
type trait 可以把结果给你。
</p>
<p>
reallyAsync 用起来就像 std::async 那样：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">auto</span> fut <span style="color:#f92672">=</span> reallyAsync(f); <span style="color:#75715e">// run f asynchronously;
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// throw if std::async
</span><span style="color:#75715e"></span>  <span style="color:#75715e">// would throw
</span></code></pre></div>
</div>
<p>
在 C++14 中，推断 reallyAsync 返回值类型的能力简化了函数声明：
</p>
<div class="src src-c++">
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-c++" data-lang="c++">  <span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> F, <span style="color:#66d9ef">typename</span>... Ts<span style="color:#f92672">&gt;</span>
  <span style="color:#66d9ef">inline</span>
  <span style="color:#66d9ef">auto</span> <span style="color:#75715e">// C++14
</span><span style="color:#75715e"></span>  reallyAsync(F<span style="color:#f92672">&amp;&amp;</span> f, Ts<span style="color:#f92672">&amp;&amp;</span>... params)
  {
	  <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>async(std<span style="color:#f92672">::</span>launch<span style="color:#f92672">::</span>async,
						std<span style="color:#f92672">::</span>forward<span style="color:#f92672">&lt;</span>F<span style="color:#f92672">&gt;</span>(f),
						std<span style="color:#f92672">::</span>forward<span style="color:#f92672">&lt;</span>Ts<span style="color:#f92672">&gt;</span>(params)...);
  }
</code></pre></div>
</div>
<p>
这个版本很清楚地让你知道 reallyAsync 除了使用 std::launch::async 发射策略调用 std::async 外，没做任何东西。
</p>
<h2 id="headline-4">
记住
</h2>
<ul>
<li>
<p>
std::async 的默认发射策略既允许任务异步执行，又允许任务同步执行。
</p>
</li>
<li>
<p>
这个灵活性（上一点）导致了使用 thread_local 变量时的不确定性，它隐含着任务可能不会执行，它还影响了基于超时的 wait 调用的程序逻辑。
</p>
</li>
<li>
<p>
如果异步执行是必需的，指定 std::launch::async 发射策略。
</p>
</li>
</ul>
<h1 id="headline-5">
参考
</h1>
<p>
原文：effective-modern-c++
翻译：<a href="http://blog.csdn.net/big_yellow_duck/article/category/635234">http://blog.csdn.net/big_yellow_duck/article/category/635234</a>
</p>

    </div>

    
<footer class="post-footer">
      <div class="post-tags">
          <a href="/tags/c&#43;&#43;/">C&#43;&#43;</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="/post/c&#43;&#43;-ep17the-concurrency-api2/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">C&#43;&#43; Ep17:The Concurrency API(2)</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="/post/c&#43;&#43;-ep15lambda-epressions2/">
            <span class="next-text nav-default">C&#43;&#43; Ep15:Lambda Epressions(2)</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  
  

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
  <a href="https://hardy5012.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
     - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author"></span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  <script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  
<script type="text/javascript" src="/dist/even.26188efa.min.js"></script>








</body>
</html>
